{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "from scipy.stats import invwishart, multivariate_normal\n",
    "#start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_person  = 1000 # draws for market share integration\n",
    "n_product = 10   # products\n",
    "n_market  = 50   # markets\n",
    "n_exp     = 5   # MC experiments\n",
    "n_draw = 1000\n",
    "n_mh = 1000\n",
    "n_pte = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# true parameters\n",
    "alpha0 = 2.0\n",
    "alpha1 = 1.5\n",
    "m_beta = -3.0\n",
    "sd_beta = 0.5\n",
    "omega0 = 1\n",
    "omega1 = 0.5\n",
    "m_xieta = [0, 0]\n",
    "sig_xieta = np.array([[1, 0.5], [0.5, 4]])\n",
    "m_x = 1\n",
    "sd_x = 0.5\n",
    "m_z = 1\n",
    "sd_z = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# product characteristic x_jt and cost shifter z_jt \n",
    "x = m_x + sd_x * np.random.randn(n_product, n_market)\n",
    "z = m_z + sd_z * np.random.randn(n_product, n_market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# correlation b/t price component and demand shock\n",
    "xieta = np.random.multivariate_normal(m_xieta, sig_xieta, (n_product, n_market))\n",
    "xi = xieta[:, :, 0]\n",
    "eta = xieta[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99807716,  0.54909072],\n",
       "       [ 0.54909072,  4.53783526]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check xi and eta\n",
    "np.cov(xi.flatten(), eta.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate p_jt\n",
    "p = omega0 + omega1*z + eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate consumer heterogeneity\n",
    "vi = np.random.randn(n_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Memory allocation\n",
    "s = np.zeros((n_product+1, n_market))\n",
    "u = np.zeros(n_product+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Simulate market share\n",
    "u[-1] = 0   ### the last product is no purchase\n",
    "for t in range(n_market):\n",
    "    for i in range(n_draw): \n",
    "        for j in range(n_product):\n",
    "            u[j] = alpha0 + alpha1 * x[j, t] + (m_beta + sd_beta*vi[i]) * p[j, t] + xi[j, t]\n",
    "        den = 0\n",
    "        for j in range(n_product+1):\n",
    "            den += math.exp(u[j]-np.max(u)) # -max_u ensures that exp() <= 1 so no blowup\n",
    "        # compute the logit choice probability for each choice\n",
    "        for j in range(n_product+1):\n",
    "            s[j, t] += math.exp(u[j]-np.max(u))/den\n",
    "            \n",
    "s /= n_draw\n",
    "print(np.sum(s, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate BLP using Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_theta1  = 3 # linear parameters\n",
    "n_theta2  = 1 # nonlinear parameters\n",
    "n_omega = 2 # pricing equation parameters\n",
    "n_obs = n_product * n_market # number of observations\n",
    "tol_blp = 0.005 # tolerance level for BLP contraction mapping\n",
    "rwsd = 0.05 # step size of random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate consumer heterogeneity\n",
    "v = np.random.randn(n_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-13-55556c88cebc>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-55556c88cebc>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    theta2 = theta2_a\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "rho = sig_xieta[0, 1]/math.sqrt(sig_xieta[0, 0]*sig_xieta[1, 1])\n",
    "# substitute accepted param for MH draws\n",
    "    theta2 = theta2_a\n",
    "    # pre-compute correlation\n",
    "    rho = sig_xieta[0, 1]/math.sqrt(sig_xieta[0, 0]*sig_xieta[1, 1])\n",
    "    # compute pllh at previously accepted theta2, theta1, omega, sig_xieta\n",
    "    pllh = log_likelihood(&par, &data, &var, &pllh, 0)\n",
    "    # candidate parameter value\n",
    "    theta2 += rwsd*np.random.randn()\n",
    "    \n",
    "          //    - given theta1, compute xi\n",
    "      //    - given omega, compute eta\n",
    "      //    - compute jacobian\n",
    "      //    - compute joint likelihood of (xi, eta)\n",
    "    \n",
    "    \n",
    "    # calculate llh at candidate parameter value\n",
    "    llh = log_likelihood(&par, &data, &var, &llh, 1)\n",
    "        # acceptance probability\n",
    "    acc_prob = min(0, llh - pllh)\n",
    "    # accept or reject\n",
    "    udraw = np.random.rand()\n",
    "    if math.log(udraw) <= acc_prob:\n",
    "        theta2_a = theta2\n",
    "        pllh = llh\n",
    "        delta_all_a = delta_all\n",
    "        xi_a = xi\n",
    "        eta_a = eta\n",
    "    else:\n",
    "        theta2 = theta2_a\n",
    "        delta_all = delta_all_a\n",
    "        xi = xi_a\n",
    "        eta = eta_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# draw theta1\n",
    "\n",
    "### given theta2, we have delta (already computed); given omega, we have eta\n",
    "### step 1. compute the mean and var of conditional dist of xi given eta\n",
    "### step 2. compute the adjusted Y (delta) and X (x)\n",
    "### step 3. compute the posterior dist of theta1\n",
    "### step 4. draw from the distribution\n",
    "\n",
    "def draw_theta1(delta_all, omega, sig_xieta):\n",
    "    eta = P - np.dot(Z, omega)\n",
    "    \n",
    "    # adjust delta and X\n",
    "    rho = sig_xieta[0, 1]/math.sqrt(sig_xieta[0, 0]*sig_xieta[1, 1])\n",
    "    cond_m = math.sqrt(sig_xieta[0, 0]/sig_xieta[1, 1])*rho*eta\n",
    "    #print(cond_m,cond_m.shape)\n",
    "    cond_sd = math.sqrt((1-rho**2)*sig_xieta[0, 0])\n",
    "    aY = (delta_all-cond_m)/cond_sd\n",
    "    aX = X/cond_sd\n",
    "\n",
    "    # compute posterior mean and variance of theta1\n",
    "    aXtX = np.dot(aX.T, aX)\n",
    "    sig_theta1 = np.linalg.inv(aXtX)\n",
    "    m_theta1 = np.dot(sig_theta1, np.dot(aX.T, aY))\n",
    "    theta1 = np.random.multivariate_normal(m_theta1, sig_theta1)   # should be a vector with 3 elements\n",
    "    \n",
    "    return theta1\n",
    "\n",
    "# update Xtheta1: note here we have to use X, not aX\n",
    "#Xtheta1 = np.dot(X, theta1)\n",
    "\n",
    "# update xi: note here we have to use delta_all, not aY\n",
    "#xi = delta_all - Xtheta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw omega\n",
    "\n",
    "### given theta2, we have delta (already computed); given theta1, we have xi\n",
    "### step 1. compute the mean and var of conditional dist of eta given xi\n",
    "### step 2. compute the adjusted Y (delta) and X (x)\n",
    "### step 3. compute the posterior dist of theta1\n",
    "### step 4. draw from the distribution\n",
    "\n",
    "def draw_omega(delta_all, theta1, sig_xieta):\n",
    "    xi = delta_all - np.dot(X, theta1)\n",
    "    \n",
    "    # adjust delta and X\n",
    "    rho = sig_xieta[0, 1]/math.sqrt(sig_xieta[0, 0]*sig_xieta[1, 1])\n",
    "    cond_m = math.sqrt(sig_xieta[1, 1]/sig_xieta[0, 0])*rho*xi\n",
    "    cond_sd = math.sqrt((1-rho**2)*sig_xieta[1, 1])\n",
    "    aP = (P-cond_m)/cond_sd\n",
    "    aZ = Z/cond_sd\n",
    "\n",
    "    # compute posterior mean and variance of theta1\n",
    "    aZtZ = np.dot(aZ.T, aZ)\n",
    "    sig_omega = np.linalg.inv(aZtZ)\n",
    "    m_omega = np.dot(sig_omega, np.dot(aZ.T, aP))\n",
    "    omega = np.random.multivariate_normal(m_omega, sig_omega)   # should be a vector with 2 elements\n",
    "    \n",
    "    return omega\n",
    "\n",
    "# update Zomega: note here we have to use Z, not aZ\n",
    "#Zomega = np.dot(Z, omega)\n",
    "\n",
    "# update eta: note here we have to use P, not aP\n",
    "#eta = P - Zomega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw sig_xieta\n",
    "\n",
    "### given theta2, we have delta (already computed); given theta1, we have xi; given omega, we have eta\n",
    "### step 1. compute the sample variance of (xi, eta)\n",
    "### step 2. compute posterior v1 (df) and S1 (scale matrix), and transform into shape and scale\n",
    "### step 3. draw from IW(shape, scale)\n",
    "\n",
    "def draw_sig_xieta(delta_all, theta1, omega):\n",
    "    # compute sample variance of (xi, eta)\n",
    "    xi = delta_all - np.dot(X, theta1)\n",
    "    eta = P - np.dot(Z, omega)\n",
    "    xieta = np.column_stack((xi, eta))\n",
    "    bar_sig = np.dot(xieta.T, xieta)# no need to divide by n_obs, as we will multiply bar_sig by n_obs\n",
    "    \n",
    "    # compute v1 and S1\n",
    "    v1 = 2 + n_obs\n",
    "    S1 = (2*np.eye(2) + bar_sig)/(2+n_obs)\n",
    "    df = v1\n",
    "    scale = v1*S1   # by Wikipedia\n",
    "\n",
    "    # draw from IW(v1, S1)\n",
    "    sig_xieta = invwishart.rvs(df, scale)   \n",
    "    \n",
    "    return sig_xieta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_mktshare_t(deltat, theta2, t):   # t is fixed, so we only consider i and j\n",
    "    pred_s = np.zeros(n_product)\n",
    "    u[-1] = 0\n",
    "    for i in range(n_person):\n",
    "        for j in range(n_product):\n",
    "            u[j] = deltat[j] + theta2*v[i]*p[j, t]\n",
    "        den = 0\n",
    "        for j in range(n_product+1):\n",
    "            den += math.exp(u[j]-np.max(u)) # -max_u ensures that exp() <= 1 so no blowup\n",
    "        # compute the logit choice probability for each choice\n",
    "        for j in range(n_product):\n",
    "            pred_s[j] += math.exp(u[j]-np.max(u))/den\n",
    "    pred_s /= n_person\n",
    "    return pred_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contraction_mapping(theta2):\n",
    "    # initialize deltas for the first iteration\n",
    "    #delta = np.zeros((n_product, n_market))\n",
    "    \n",
    "    # we can do this for each t, as markets are independent\n",
    "    for t in range(n_market):\n",
    "        dconv = 10000\n",
    "        # initialize deltat for the first iteration\n",
    "        deltat = np.log(s[:-1, t]/s[-1, t])\n",
    "        obs_s = s[:-1, t]\n",
    "        #print(obs_s)\n",
    "        while dconv > tol_blp:\n",
    "            # 1. given delta, compute predicted marekt shares\n",
    "            pred_s = pred_mktshare_t(deltat, theta2, t)\n",
    "            # 2. update delta\n",
    "            deltan = deltat + np.log(np.divide(obs_s, pred_s))\n",
    "            # 3. compute difference from previous delta\n",
    "            dconv = np.max(np.abs(deltan-deltat))\n",
    "            deltat = deltan\n",
    "            #print(\"deltat mean:\", np.mean(deltat))\n",
    "        delta[:, t] = deltan\n",
    "        #print(\"converged\", t, dconv)  \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the jacobian for market t\n",
    "def jacobian_det(deltat, theta2, t):\n",
    "    # calculate market share for each person i\n",
    "    si = np.zeros((n_person, n_product))\n",
    "    u[-1] = 0   ### the last product is no purchase\n",
    "    for i in range(n_person): \n",
    "        for j in range(n_product):\n",
    "            u[j] = deltat[j] + theta2*v[i]*p[j, t]\n",
    "        den = 0\n",
    "        for j in range(n_product+1):\n",
    "            den += math.exp(u[j]-np.max(u)) # -max_u ensures that exp() <= 1 so no blowup\n",
    "        # compute the logit choice probability for each choice\n",
    "        for j in range(n_product):\n",
    "            si[i, j] = math.exp(u[j]-np.max(u))/den\n",
    "    \n",
    "    # calculate Jacobian matrix and its invdet\n",
    "    jacobian_t = np.zeros((n_product, n_product))\n",
    "    for j in range(n_product):\n",
    "        for k in range(n_product):\n",
    "            if j == k:\n",
    "                for i in range(n_person):\n",
    "                    jacobian_t[j, k] += si[i, j]*(1-si[i, j])\n",
    "            else:\n",
    "                for i in range(n_person):\n",
    "                    jacobian_t[j, k] -= si[i, j]*si[i, k]\n",
    "    jacobian_t /= n_person\n",
    "    det = np.linalg.det(jacobian_t)\n",
    "    \n",
    "    return det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta = contraction_mapping(theta2_a)\n",
    "delta1 = delta[:, 0]\n",
    "delta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jacobian_det(delta1, theta2_a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood(theta1, theta2, omega, sig_xieta, delta):\n",
    "    \n",
    "    # step 1: given theta2 (par.sd_beta in this exercise), compute delta\n",
    "    delta_all = delta.flatten()\n",
    "    #print(delta_all)\n",
    "    \n",
    "    # step 2: given delta and theta1 (previously accepted), compute xi as the residual\n",
    "    Xtheta1 = np.dot(X, theta1)\n",
    "    xi = delta_all - Xtheta1\n",
    "    \n",
    "    # step 3: given delta and omega (previously accepted), compute eta as the residual\n",
    "    Zomega = np.dot(Z, omega)\n",
    "    eta = P - Zomega\n",
    "    \n",
    "    # step 4: compute the Jacobian and likelihood\n",
    "    llh = 0\n",
    "    for i in range(n_obs):\n",
    "        llh += multivariate_normal.logpdf([xi[i], eta[i]], mean = np.array([0, 0]), cov = sig_xieta)\n",
    "    for t in range(n_market):\n",
    "        deltat = delta[:, t]\n",
    "        llh -= math.log(jacobian_det(deltat, theta2, t))\n",
    "        \n",
    "    return llh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0. initialization\n",
    "delta = np.zeros((n_product, n_market))\n",
    "hist_theta = np.zeros((int(n_mh/10), n_pte))\n",
    "# 1. substitute\n",
    "X = np.column_stack((np.ones(n_obs), x.flatten(), p.flatten()))\n",
    "Z = np.column_stack((np.ones(n_obs), z.flatten()))\n",
    "P = p.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta2_a = np.array([0.5])\n",
    "theta1 = np.array([2, 1.5, -3])\n",
    "omega = np.array([1, 0.5])\n",
    "sig_xieta = np.array([[1, 0.5], [0.5, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pllh = log_likelihood(theta1, theta2_a, omega, sig_xieta, flg=1) \n",
    "pllh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after draw_theta1 [ 1.3301288   1.53197819 -2.93529268] [ 1.   0.5] [[ 1.   0.5]\n",
      " [ 0.5  4. ]] [ 0.5]\n",
      "after draw_omega [ 1.3301288   1.53197819 -2.93529268] [ 1.54972623  0.03150747] [[ 1.   0.5]\n",
      " [ 0.5  4. ]] [ 0.5]\n",
      "after draw_sig_xieta [ 1.3301288   1.53197819 -2.93529268] [ 1.54972623  0.03150747] [[ 1.49160078  0.64890003]\n",
      " [ 0.64890003  4.24175379]] [ 0.5]\n",
      "pllh 2555.69990839\n",
      "llh 2563.75173507\n",
      "accept\n",
      "\n",
      " nimh = 0 / 1000: llh = 2555.699908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MCMC loop: this version draws all alpha and betai jointly\n",
    "for imh in range(1): #n_mh\n",
    "    # step 1: draw theta1, omega, sig_xieta given theta2\n",
    "    # given theta2_a, get delta\n",
    "    delta_a = contraction_mapping(theta2_a)\n",
    "    delta_all = delta_a.flatten()\n",
    "    #print(delta_all)\n",
    "    # Bayesian linear regression\n",
    "    theta1 = draw_theta1(delta_all, omega, sig_xieta)\n",
    "    print(\"after draw_theta1\", theta1, omega, sig_xieta, theta2_a)\n",
    "    omega = draw_omega(delta_all, theta1, sig_xieta)\n",
    "    print(\"after draw_omega\", theta1, omega, sig_xieta, theta2_a)\n",
    "    sig_xieta = draw_sig_xieta(delta_all, theta1, omega)\n",
    "    print(\"after draw_sig_xieta\", theta1, omega, sig_xieta, theta2_a)\n",
    "    \n",
    "    # step 2: draw theta2 given theta1, omega, sig_xieta using MH\n",
    "    # calculate pllh at previously accepted theta2_a\n",
    "    pllh = log_likelihood(theta1, theta2_a, omega, sig_xieta, delta=delta_a)\n",
    "    print(\"pllh\", pllh)\n",
    "    # draw candidate theta2\n",
    "    theta2_c = theta2_a + rwsd*np.random.randn()\n",
    "    # calculate llh at candidate theta2\n",
    "    delta_c = contraction_mapping(theta2_c)\n",
    "    llh = log_likelihood(theta1, theta2_c, omega, sig_xieta, delta=delta_c)\n",
    "    print(\"llh\", llh)\n",
    "    # acceptance probability\n",
    "    acc_prob = min(0, llh - pllh)\n",
    "    # accept or reject\n",
    "    udraw = np.random.rand()\n",
    "    if math.log(udraw) <= acc_prob:\n",
    "        theta2_a = theta2_c\n",
    "        print(\"accept\")\n",
    "    else:\n",
    "        print(\"reject\")\n",
    "\n",
    "    # display progress (every 100 iter)\n",
    "    if imh % 100 == 0:\n",
    "        print(\"\\n nimh = %ld / %ld: llh = %f\\n\" % (imh, n_mh, pllh))\n",
    "    # store mcmc draws (every 10 iter)\n",
    "    if imh % 10 == 0:\n",
    "        hist_theta[int(imh/10)] = np.concatenate((theta1, theta2_a, omega, sig_xieta.flatten()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4639.568480968475 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.73463301,  1.49597946, -2.4909917 ,  0.99653677,  1.30760316,\n",
       "         0.09178961,  0.96104409, -0.07463332, -0.07463332,  4.34661573],\n",
       "       [ 1.78462148,  1.52393029, -2.52034542,  0.99653677,  1.22261839,\n",
       "         0.16557541,  1.02238012,  0.07649231,  0.07649231,  3.90441875],\n",
       "       [ 1.73957375,  1.56796414, -2.57395822,  0.99653677,  0.88050197,\n",
       "         0.54960988,  1.01555044,  0.54934019,  0.54934019,  4.10946835],\n",
       "       [ 1.79107012,  1.46334513, -2.55747452,  0.99653677,  1.38370495,\n",
       "        -0.02957648,  1.03995323,  0.32017673,  0.32017673,  4.1885823 ],\n",
       "       [ 1.8572622 ,  1.53248534, -2.6579226 ,  0.99653677,  1.44755284,\n",
       "         0.09666447,  1.06198121,  0.69026811,  0.69026811,  4.67544975],\n",
       "       [ 1.95918837,  1.49221214, -2.71598704,  0.99653677,  1.28678771,\n",
       "         0.02544704,  1.32758368,  1.10216   ,  1.10216   ,  4.88626249],\n",
       "       [ 1.99237644,  1.62686514, -2.77338064,  0.99653677,  1.31428382,\n",
       "         0.1359178 ,  1.36451009,  1.2248183 ,  1.2248183 ,  4.39691375],\n",
       "       [ 2.2133969 ,  1.42695487, -2.84211105,  0.99653677,  1.06228703,\n",
       "         0.30824776,  1.63732274,  1.54296284,  1.54296284,  4.24342289],\n",
       "       [ 1.895114  ,  1.73119452, -2.84710089,  0.99653677,  1.19872187,\n",
       "         0.23003111,  1.61774612,  1.59982267,  1.59982267,  4.20008767],\n",
       "       [ 2.22052872,  1.42600523, -2.88270092,  0.99653677,  1.12946244,\n",
       "         0.20167849,  1.6949533 ,  1.6205609 ,  1.6205609 ,  4.40031867],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.05612089  1.54064638 -2.81225611  0.99653677  1.19830857  0.18026444\n",
      "  1.52842318  1.41806494  1.41806494  4.4254011 ] [  1.35017158e-01   1.20130342e-01   5.97444274e-02   1.11022302e-16\n",
      "   9.43616849e-02   9.51315578e-02   1.51508407e-01   2.12969562e-01\n",
      "   2.12969562e-01   2.44014790e-01]\n"
     ]
    }
   ],
   "source": [
    "# compute posterior mean and sd (burn-in 0.5*n_mh)\n",
    "theta = hist_theta[5:10]#[int(n_mh/20):]\n",
    "m_theta = np.mean(theta, axis = 0)\n",
    "sd_theta = np.std(theta, axis = 0)\n",
    "print(m_theta, sd_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.29083008,  1.64733493, -2.36242308,  0.99653677,  1.09946362,\n",
       "        0.20617327,  1.00475057, -0.489418  , -0.489418  ,  3.78718813])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_theta[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### check: whether the calculation of  bar_sig in the sample code is the same as what we use\n",
    "xi = np.random.randn(n_obs)\n",
    "eta = np.random.randn(n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar_sig = np.zeros((2,2))\n",
    "for i_obs in range(n_obs):\n",
    "    bar_sig[0][0] += xi[i_obs]*xi[i_obs]\n",
    "    bar_sig[0][1] += xi[i_obs]*eta[i_obs]\n",
    "    bar_sig[1][1] += eta[i_obs]*eta[i_obs]\n",
    "bar_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try2 = np.column_stack((xi, eta))\n",
    "bar_sig2 = np.dot(try2.T, try2)\n",
    "bar_sig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
